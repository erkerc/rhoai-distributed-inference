apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  name: qwen3-8b-llmd
  namespace: llmd-demo
spec:
  replicas: 3
  model:
   # uri: pvc://model-storage/RedHatAI/Qwen3-8B-FP8-dynamic
    uri: oci://registry.redhat.io/rhelai1/modelcar-qwen3-8b-fp8-dynamic:1.5
    name: RedHatAI/Qwen3-8B-FP8-dynamic
  router:
    gateway: {}
    route: {}
    scheduler: {}
  template:
    containers:
      - name: main
        env:
          # disable uvicorn access log to reduce log noise
          - name: VLLM_ADDITIONAL_ARGS
            value: "--disable-uvicorn-access-log --max-model-len=4096"
        resources:
          limits:
            cpu: '4'
            memory: 16Gi
            nvidia.com/gpu: '1'
          requests:
            cpu: '1'
            memory: 8Gi
            nvidia.com/gpu: '1'
        livenessProbe:
          initialDelaySeconds: 10
        startupProbe:
          httpGet:
            path: /health
            port: 8000
            scheme: HTTPS
          initialDelaySeconds: 15
          timeoutSeconds: 10
          periodSeconds: 10
          failureThreshold: 60
    
    nodeSelector:
      node.kubernetes.io/instance-type: "g5.2xlarge"
    tolerations:
    - key: "nvidia.com/gpu"
      operator: "Equal"
      value: "NVIDIA-A10G-SHARED"
      effect: "NoSchedule"
